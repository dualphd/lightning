{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2de31bd-21d7-4efa-885d-4b08f525137e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import h5py\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de856a5-e420-45b4-9166-1dbf43c524f2",
   "metadata": {},
   "source": [
    "# Make data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ba4d6d-945f-4a7c-bce2-5b7ca674a01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data load\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "# normalization\n",
    "x_train = x_train.astype(np.float32)/255.\n",
    "x_test = x_test.astype(np.float32)/255.\n",
    "\n",
    "# flatten\n",
    "x_train = x_train.reshape((-1, 28, 28, 1))\n",
    "y_train = y_train.reshape((-1,  1))\n",
    "x_test = x_test.reshape((-1, 28,28, 1))\n",
    "y_test = y_test.reshape((-1, 1))\n",
    " \n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "print(y_test.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428ad654-07d6-4652-a728-37c80be1ceda",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('myfile_train_x.hdf5', 'w') as f:\n",
    "    group_x = f.create_group('x')\n",
    "    \n",
    "    print(group_x.name)\n",
    "    print(list(f.keys()))\n",
    "\n",
    "    group_x.create_dataset('image', data=x_train, dtype=np.float32)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1080a46-07fb-49d1-abc6-26bd53da1b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('myfile_train_y.hdf5', 'w') as f:\n",
    "    \n",
    "    group_y = f.create_group('y')\n",
    "    print(group_y.name)\n",
    "    print(list(f.keys()))\n",
    "    \n",
    "    group_y.create_dataset('label', data=y_train, dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3911526b-eb80-40a3-bea0-940f8bff38d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('myfile_test_x.hdf5', 'w') as f:\n",
    "    group_x = f.create_group('x')\n",
    "    \n",
    "    print(group_x.name)\n",
    "    print(list(f.keys()))\n",
    "\n",
    "    group_x.create_dataset('image', data=x_train, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d93680d-1e54-4ece-b8ff-14923a3fc242",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('myfile_test_y.hdf5', 'w') as f:\n",
    "    \n",
    "    group_y = f.create_group('y')\n",
    "    print(group_y.name)\n",
    "    print(list(f.keys()))\n",
    "    \n",
    "    group_y.create_dataset('label', data=y_train, dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff64ff51-8b3f-43bf-b65f-76463f096664",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8130080-b9e5-468e-b6fb-10a935c0532b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFAR10PyDataset(tf.keras.utils.Sequence):\n",
    "\n",
    "    def __init__(self, path, keyword, batch_size, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.path = path\n",
    "        self.keyword = keyword \n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.f = h5py.File(path, 'r')\n",
    "\n",
    "        group_key = list(self.f.keys())[0]\n",
    "\n",
    "        self.data = self.f[group_key][keyword]\n",
    "        self.dsize = len(self.data)\n",
    "        \n",
    "        \n",
    "        print('dsize:', self.dsize)\n",
    "        \n",
    " \n",
    "\n",
    "    def __del__(self):\n",
    "        self.f.close()\n",
    "\n",
    "    def __len__(self):\n",
    "        # Return number of batches.\n",
    "        return math.ceil(self.dsize / self.batch_size)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Return x, y for batch idx.\n",
    "        low = idx * self.batch_size\n",
    "        # Cap upper bound at array length; the last batch may be smaller\n",
    "        # if the total number of items is not a multiple of batch size.\n",
    "        high = min(low + self.batch_size, self.dsize)\n",
    "        batch = self.data[low:high]\n",
    "\n",
    "        return batch, batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74b21a7-9000-40ca-9d49-f901e9538df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_x = CIFAR10PyDataset(\"./myfile_train_x.hdf5\", \"image\", 128)\n",
    "data_train_y = CIFAR10PyDataset(\"./myfile_train_y.hdf5\", \"label\", 128)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31de2ab-e33c-4ce9-b1d4-0c5604c2046c",
   "metadata": {},
   "source": [
    "# make model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09905b13-c259-41f7-85cf-2c5363334a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e7046e-8734-481a-be35-5f11b9e4776a",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.layers.Input(shape=input_shape, name='input')\n",
    "layer1 = tf.keras.layers.Conv2D(4, (3,3), strides=1, activation=\"relu\", padding='same', name=\"layer1\")\n",
    "layer2 = tf.keras.layers.Conv2D(16, (3,3), strides=2, activation=\"relu\", padding='same', name=\"layer2\")\n",
    "layer3 = tf.keras.layers.Conv2D(32, (3,3), strides=2, activation=\"relu\", padding='same', name=\"layer3\") \n",
    "layer4 = tf.keras.layers.Conv2D(64, (3,3), strides=1, activation=\"relu\", padding='same', name=\"layer4\")\n",
    "layer5 = tf.keras.layers.Conv2DTranspose(32, (3,3), strides=2, activation=\"relu\", padding='same', name=\"layer5\")\n",
    "layer6 = tf.keras.layers.Conv2DTranspose(16, (3,3), strides=2, activation=\"relu\", padding='same', name=\"layer6\")\n",
    "layer7 = tf.keras.layers.Conv2D(4, (3,3), strides=1, activation=\"relu\", padding='same', name=\"layer7\")\n",
    "layer8 = tf.keras.layers.Conv2D(1, (3,3), strides=1, activation=\"relu\", padding='same', name=\"layer8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3df381-2528-47eb-bc7a-7b68383d3492",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = layer1(inputs)\n",
    "x = layer2(x)\n",
    "x = layer3(x)\n",
    "x = layer4(x)\n",
    "x = layer5(x)\n",
    "x = layer6(x)\n",
    "x = layer7(x)\n",
    "x = layer8(x)\n",
    "model = tf.keras.models.Model(inputs, x, name=\"autoencoder\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc9868e-4a48-4883-b95c-0a6384f95b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model_structure.h5', include_optimizer=False)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c0b324-374a-4adb-8941-123e5300238f",
   "metadata": {},
   "source": [
    "## compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60da539a-063f-4b90-9cba-6d2075c6bd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mse\", optimizer=tf.keras.optimizers.Adam(), metrics=[\"mse\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3964eb9-d85e-4e69-a914-3a2aa7c674e6",
   "metadata": {},
   "source": [
    "# Callbacks For Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd40637-5b16-4a42-ba13-b09e63266ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_callbacks(names, base_path, model_name=None, dataloader=None, is_weights_only=False):\n",
    "    callbacks=[]\n",
    "    # callbacks =  tf.keras.callbacks.CallbackList()\n",
    "    if 'ckeckpoint' in names:\n",
    "        ckpt_dir = os.path.join(base_path, 'checkpoint', model_name )\n",
    "        \n",
    "        print(ckpt_dir)\n",
    "        os.makedirs(ckpt_dir, exist_ok=True)\n",
    "\n",
    "        if is_weights_only:\n",
    "            ckeckpoint_dir = os.path.join(ckpt_dir, '{epoch:05d}_%s_{loss:.5e}.keras' % (model_name)) \n",
    "        else\n",
    "            ckeckpoint_dir = os.path.join(ckpt_dir, '{epoch:05d}_%s_{loss:.5e}.weights.h5' % (model_name))\n",
    "        callback_ckpt = tf.keras.callbacks.ModelCheckpoint(\n",
    "                                filepath = ckeckpoint_dir,\n",
    "                                monitor='val_loss',\n",
    "                                verbose=1,\n",
    "                                save_best_only=False,\n",
    "                                save_weights_only=is_weights_only,\n",
    "                                initial_value_threshold=initial_value_threshold )\n",
    "        callbacks.append(callback_ckpt)\n",
    "    if 'tensorboard' in names:\n",
    "        tb_dir = os.path.join(base_path, 'board', model_name)\n",
    "        os.makedirs(tb_dir, exist_ok=True)\n",
    "        callback_tb = tf.keras.callbacks.TensorBoard( log_dir=tb_dir,\n",
    "                                                       histogram_freq=10,\n",
    "                                                       write_graph=True,\n",
    "                                                       write_images=False)\n",
    "        callbacks.append(callback_tb)\n",
    "\n",
    "    return callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55022f99-9041-4420-941f-fa144199c3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = get_training_callbacks(['ckeckpoint', 'tensorboard', ],\n",
    "                                    base_path=\".\", model_name=\"autoencoder\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50466f8e-ff65-4013-88ea-529db11c2e96",
   "metadata": {},
   "source": [
    "# Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b05a8e2-77b4-480a-97c1-4742e7d3908b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62dbc8b-1ff4-4157-989c-cbe461e5dd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = os.path.join('board', 'autoencoder','train')\n",
    "%tensorboard --logdir=model_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a43f12a-6d53-4462-af2d-e4631200a4ca",
   "metadata": {},
   "source": [
    "# Lets Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14713934-3bbb-468f-8db1-065cabfc5fc3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# strategy = tf.distribute.MirroredStrategy()\n",
    "# with strategy.scope():\n",
    "\n",
    "\n",
    "model.fit(x=data_train_x, \n",
    "          epochs=100, \n",
    "          callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0538e999-fd7e-4b12-9cac-b24a45148132",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a432e2ab-d2bf-4da5-a5b1-a5032a8d4201",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
